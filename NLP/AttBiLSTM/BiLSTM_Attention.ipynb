{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from tqdm import tqdm   \n",
    "import jieba    \n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import *\n",
    "\n",
    "os.chdir(sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'..\\data\\online_shopping_10_cats\\online_shopping_10_cats.csv'\n",
    "pd_all = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评论数目（总体）：62774\n",
      "评论数目（正向）：31728\n",
      "评论数目（负向）：31046\n"
     ]
    }
   ],
   "source": [
    "print('评论数目（总体）：%d' % pd_all.shape[0])\n",
    "print('评论数目（正向）：%d' % pd_all[pd_all.label==1].shape[0])\n",
    "print('评论数目（负向）：%d' % pd_all[pd_all.label==0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat  label                                             review\n",
       "0  书籍      1  ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...\n",
       "1  书籍      1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...\n",
       "2  书籍      1  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...\n",
       "3  书籍      1  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...\n",
       "4  书籍      1  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path,sample_ratio=1):\n",
    "    pd_all = pd.read_csv(file_path)\n",
    "    total_length = pd_all.shape[0]\n",
    "    labels = list(pd_all.loc[:,'label'].astype(str))\n",
    "    reviews = list(pd_all.loc[:,'review'].astype(str))\n",
    "    ratio_num = int(total_length * sample_ratio)\n",
    "    return reviews[0:ratio_num],labels[0:ratio_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews,labels = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持一颗年轻的心。我想，这是他能很好的和孩子沟通的一个重要因素。读刘墉的文章，总能让我看到一个快乐的平易近人的父亲，他始终站在和孩子同样的高度，给孩子创造着一个充满爱和自由的生活环境。很喜欢刘墉在字里行间流露出的做父母的那种小狡黠，让人总是忍俊不禁，父母和子女之间有时候也是一种战斗，武力争斗过于低级了，智力较量才更有趣味。所以，做父母的得加把劲了，老思想老观念注定会一败涂地，生命不息，学习不止。家庭教育，真的是乐在其中。\n"
     ]
    }
   ],
   "source": [
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/62774 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\HZH\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.719 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "100%|██████████| 62774/62774 [00:16<00:00, 3864.20it/s]\n"
     ]
    }
   ],
   "source": [
    "vocabs = []\n",
    "for item in tqdm(reviews):\n",
    "    vocabs.extend(jieba.cut(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2359953"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68495"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_vocabs = list(set(vocabs))\n",
    "len(set_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62774/62774 [00:15<00:00, 3987.56it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for item in tqdm(reviews):\n",
    "    sentences.append(list(jieba.cut(item)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62774/62774 [00:15<00:00, 4114.71it/s]\n"
     ]
    }
   ],
   "source": [
    "vocabs_len = []\n",
    "for item in tqdm(reviews):\n",
    "    vocabs_len.append(len(list(jieba.cut(item))))   # 分词后的长度\n",
    "pd_all['review_len'] = vocabs_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    62774.000000\n",
       "mean        37.594434\n",
       "std         49.913748\n",
       "min          1.000000\n",
       "50%         23.000000\n",
       "95%        117.000000\n",
       "max       1795.000000\n",
       "Name: review_len, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_all['review_len'].describe(percentiles=[.5,.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 只保留出现频率大于15的词,偏僻词等略过,如果计算资源充足的，可以自行调整频率大小\n",
    "Freq = 15\n",
    "word_freq_file = '..\\data\\online_shopping_10_cats\\word_freq.txt'\n",
    "with open(word_freq_file,\"w\",encoding='utf-8',) as fout:\n",
    "    for word,freq in dict(Counter(vocabs)).items():\n",
    "        if freq>Freq:\n",
    "            fout.write(word+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7470"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(word_freq_file, encoding='utf-8') as fin:\n",
    "    vocab = [i.strip() for i in fin]\n",
    "vocab=set(vocab)\n",
    "word2idx = {i:index for index, i in enumerate(vocab)}\n",
    "idx2word = {index:i for index, i in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_id = word2idx['的']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 110\n",
    "#对输入数据进行预处理,主要是对句子用索引表示且对句子进行截断与padding，将填充使用”的“来。\n",
    "def tokenizer(pd_all,pad_id):   # 分词\n",
    "    inputs = []\n",
    "    sentence_char = [list(jieba.cut(item)) for item in pd_all[\"review\"].astype(str)]    \n",
    "    # 将输入文本进行padding\n",
    "    for index,item in enumerate(sentence_char):\n",
    "        ### 若查找不存在，则返回第二个参数设置的默认值\n",
    "        temp=[word2idx.get(item_item,pad_id) for item_item in item]#表示如果词表中没有这个稀有词，无法获得，那么就默认返回pad_id。\n",
    "        if(len(item)<sequence_length):\n",
    "            for _ in range(sequence_length-len(item)):\n",
    "                temp.append(pad_id)\n",
    "        else:\n",
    "            temp = temp[:sequence_length]\n",
    "        inputs.append(temp)\n",
    "    return inputs\n",
    "\n",
    "data_input = tokenizer(pd_all,pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 创建一个关于sentences的迭代对象，返回的是一个生成器\n",
    "class genrate_sentence(object):\n",
    "    def __init__(self,sentences):\n",
    "        self.sentences = sentences\n",
    "\n",
    "    def __iter__(self):\n",
    "        for item in self.sentences:\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num = len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 利用gensim创建word2vec模型\n",
    "def create_word2vec_model(sentences,total_examples=total_num,vector_size=100,window=5,min_count=15):\n",
    "    model = Word2Vec(sentences,vector_size=vector_size,window=window,min_count=min_count)\n",
    "    ### 训练模型\n",
    "    model.train(sentences,total_examples=total_num,epochs=10)\n",
    "    ### 保存模型\n",
    "    model.save('..\\data\\online_shopping_10_cats\\word2vec_model.pkl')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = create_word2vec_model(genrate_sentence(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 保存词向量\n",
    "word_vector = word2vec_model.wv\n",
    "word_vector.save('..\\data\\online_shopping_10_cats\\word_vector.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = KeyedVectors.load('..\\data\\online_shopping_10_cats\\word_vector.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'，': 0,\n",
       " '的': 1,\n",
       " '。': 2,\n",
       " '了': 3,\n",
       " '！': 4,\n",
       " ' ': 5,\n",
       " '很': 6,\n",
       " '是': 7,\n",
       " '我': 8,\n",
       " '也': 9,\n",
       " '好': 10,\n",
       " '不': 11,\n",
       " ',': 12,\n",
       " '都': 13,\n",
       " '就': 14,\n",
       " '买': 15,\n",
       " '不错': 16,\n",
       " '还': 17,\n",
       " '在': 18,\n",
       " '有': 19,\n",
       " '没有': 20,\n",
       " '酒店': 21,\n",
       " '用': 22,\n",
       " '.': 23,\n",
       " '京东': 24,\n",
       " '和': 25,\n",
       " '说': 26,\n",
       " '房间': 27,\n",
       " '给': 28,\n",
       " '可以': 29,\n",
       " '、': 30,\n",
       " '这': 31,\n",
       " '就是': 32,\n",
       " '到': 33,\n",
       " '非常': 34,\n",
       " '一个': 35,\n",
       " '感觉': 36,\n",
       " '还是': 37,\n",
       " '？': 38,\n",
       " '没': 39,\n",
       " '这个': 40,\n",
       " '服务': 41,\n",
       " '质量': 42,\n",
       " '人': 43,\n",
       " '比较': 44,\n",
       " '上': 45,\n",
       " '苹果': 46,\n",
       " '要': 47,\n",
       " '看': 48,\n",
       " '去': 49,\n",
       " '喜欢': 50,\n",
       " '东西': 51,\n",
       " '太': 52,\n",
       " '不是': 53,\n",
       " '又': 54,\n",
       " '小': 55,\n",
       " '但': 56,\n",
       " '我们': 57,\n",
       " '大': 58,\n",
       " '价格': 59,\n",
       " '让': 60,\n",
       " '什么': 61,\n",
       " '但是': 62,\n",
       " '吧': 63,\n",
       " '你': 64,\n",
       " '差': 65,\n",
       " '住': 66,\n",
       " '而且': 67,\n",
       " '多': 68,\n",
       " '个': 69,\n",
       " '…': 70,\n",
       " '知道': 71,\n",
       " '自己': 72,\n",
       " '再': 73,\n",
       " '才': 74,\n",
       " '满意': 75,\n",
       " '会': 76,\n",
       " '啊': 77,\n",
       " '有点': 78,\n",
       " '：': 79,\n",
       " '对': 80,\n",
       " '比': 81,\n",
       " '不好': 82,\n",
       " '挺': 83,\n",
       " '问题': 84,\n",
       " '快递': 85,\n",
       " '收到': 86,\n",
       " '能': 87,\n",
       " '吃': 88,\n",
       " '手机': 89,\n",
       " '2': 90,\n",
       " '裤子': 91,\n",
       " '来': 92,\n",
       " '时候': 93,\n",
       " '一般': 94,\n",
       " '快': 95,\n",
       " '还有': 96,\n",
       " '一样': 97,\n",
       " '?': 98,\n",
       " '入住': 99,\n",
       " '方便': 100,\n",
       " '后': 101,\n",
       " '真的': 102,\n",
       " '这样': 103,\n",
       " '一直': 104,\n",
       " '~': 105,\n",
       " '包装': 106,\n",
       " '；': 107,\n",
       " '蒙牛': 108,\n",
       " '!': 109,\n",
       " '物流': 110,\n",
       " '着': 111,\n",
       " '速度': 112,\n",
       " '过': 113,\n",
       " '以后': 114,\n",
       " '不过': 115,\n",
       " '3': 116,\n",
       " '舒服': 117,\n",
       " '客服': 118,\n",
       " '特别': 119,\n",
       " '一次': 120,\n",
       " '不能': 121,\n",
       " '穿': 122,\n",
       " '*': 123,\n",
       " '很多': 124,\n",
       " '他': 125,\n",
       " '味道': 126,\n",
       " '送': 127,\n",
       " '1': 128,\n",
       " '）': 129,\n",
       " '现在': 130,\n",
       " '一点': 131,\n",
       " '因为': 132,\n",
       " '前台': 133,\n",
       " '购买': 134,\n",
       " '下次': 135,\n",
       " '屏幕': 136,\n",
       " '觉得': 137,\n",
       " '已经': 138,\n",
       " '早餐': 139,\n",
       " '差评': 140,\n",
       " '（': 141,\n",
       " '想': 142,\n",
       " '本书': 143,\n",
       " '中': 144,\n",
       " '时': 145,\n",
       " '不会': 146,\n",
       " '垃圾': 147,\n",
       " '月': 148,\n",
       " '第一次': 149,\n",
       " '里': 150,\n",
       " '跟': 151,\n",
       " '把': 152,\n",
       " '这次': 153,\n",
       " '这么': 154,\n",
       " '值得': 155,\n",
       " '支持': 156,\n",
       " '如果': 157,\n",
       " '被': 158,\n",
       " '效果': 159,\n",
       " '呢': 160,\n",
       " '得': 161,\n",
       " '4': 162,\n",
       " '便宜': 163,\n",
       " '应该': 164,\n",
       " '“': 165,\n",
       " '很快': 166,\n",
       " '”': 167,\n",
       " '最': 168,\n",
       " '起来': 169,\n",
       " '发现': 170,\n",
       " '一': 171,\n",
       " '点': 172,\n",
       " '等': 173,\n",
       " '所以': 174,\n",
       " '高': 175,\n",
       " '希望': 176,\n",
       " '大家': 177,\n",
       " '设施': 178,\n",
       " '失望': 179,\n",
       " '怎么': 180,\n",
       " '不要': 181,\n",
       " '一下': 182,\n",
       " '朋友': 183,\n",
       " '晚上': 184,\n",
       " '书': 185,\n",
       " '华为': 186,\n",
       " '5': 187,\n",
       " '购物': 188,\n",
       " '吗': 189,\n",
       " '与': 190,\n",
       " '性价比': 191,\n",
       " '下': 192,\n",
       " '水果': 193,\n",
       " '元': 194,\n",
       " '从': 195,\n",
       " '使用': 196,\n",
       " '时间': 197,\n",
       " '虽然': 198,\n",
       " '结果': 199,\n",
       " '服务员': 200,\n",
       " '其他': 201,\n",
       " '新鲜': 202,\n",
       " '做': 203,\n",
       " '坏': 204,\n",
       " '平板': 205,\n",
       " '系统': 206,\n",
       " '她': 207,\n",
       " '态度': 208,\n",
       " '携程': 209,\n",
       " '好吃': 210,\n",
       " '衣服': 211,\n",
       " '超市': 212,\n",
       " '看到': 213,\n",
       " '里面': 214,\n",
       " '那么': 215,\n",
       " '推荐': 216,\n",
       " '只有': 217,\n",
       " '他们': 218,\n",
       " '更': 219,\n",
       " '功能': 220,\n",
       " '评价': 221,\n",
       " '那': 222,\n",
       " '活动': 223,\n",
       " '孩子': 224,\n",
       " '环境': 225,\n",
       " '合适': 226,\n",
       " '可能': 227,\n",
       " '送货': 228,\n",
       " '好评': 229,\n",
       " '货': 230,\n",
       " '找': 231,\n",
       " '洗发水': 232,\n",
       " '大小': 233,\n",
       " '真是': 234,\n",
       " '日': 235,\n",
       " '年': 236,\n",
       " '为': 237,\n",
       " '完': 238,\n",
       " '选择': 239,\n",
       " '它': 240,\n",
       " '只能': 241,\n",
       " '居然': 242,\n",
       " '不到': 243,\n",
       " '烂': 244,\n",
       " '地方': 245,\n",
       " '换': 246,\n",
       " '两个': 247,\n",
       " '只是': 248,\n",
       " '你们': 249,\n",
       " '实在': 250,\n",
       " '宾馆': 251,\n",
       " '干净': 252,\n",
       " '服务态度': 253,\n",
       " '建议': 254,\n",
       " '颜色': 255,\n",
       " '开始': 256,\n",
       " '打开': 257,\n",
       " '产品': 258,\n",
       " '洗': 259,\n",
       " '需要': 260,\n",
       " '电话': 261,\n",
       " '以前': 262,\n",
       " '实惠': 263,\n",
       " '有些': 264,\n",
       " '很大': 265,\n",
       " '房': 266,\n",
       " '像': 267,\n",
       " '声音': 268,\n",
       " '第二天': 269,\n",
       " '6': 270,\n",
       " '客人': 271,\n",
       " '拿': 272,\n",
       " '小时': 273,\n",
       " '这家': 274,\n",
       " '总体': 275,\n",
       " '做工': 276,\n",
       " '今天': 277,\n",
       " '之前': 278,\n",
       " '一些': 279,\n",
       " '问': 280,\n",
       " '发货': 281,\n",
       " '正品': 282,\n",
       " '～': 283,\n",
       " '头发': 284,\n",
       " '根本': 285,\n",
       " '电池': 286,\n",
       " '哦': 287,\n",
       " '图片': 288,\n",
       " '外观': 289,\n",
       " '为什么': 290,\n",
       " '而': 291,\n",
       " '号': 292,\n",
       " '之后': 293,\n",
       " '直接': 294,\n",
       " '可': 295,\n",
       " '这种': 296,\n",
       " '真': 297,\n",
       " '却': 298,\n",
       " '10': 299,\n",
       " '来说': 300,\n",
       " '只': 301,\n",
       " '打': 302,\n",
       " '出来': 303,\n",
       " '算': 304,\n",
       " '下单': 305,\n",
       " '刚': 306,\n",
       " '还会': 307,\n",
       " '适合': 308,\n",
       " '一天': 309,\n",
       " '这里': 310,\n",
       " '好看': 311,\n",
       " '啦': 312,\n",
       " '贵': 313,\n",
       " '装': 314,\n",
       " '最后': 315,\n",
       " '连': 316,\n",
       " '离': 317,\n",
       " '超级': 318,\n",
       " '位置': 319,\n",
       " '完全': 320,\n",
       " '确实': 321,\n",
       " '7': 322,\n",
       " '打电话': 323,\n",
       " '假货': 324,\n",
       " '网上': 325,\n",
       " '不如': 326,\n",
       " '穿着': 327,\n",
       " '的话': 328,\n",
       " '竟然': 329,\n",
       " '内存': 330,\n",
       " '个头': 331,\n",
       " '并': 332,\n",
       " '是不是': 333,\n",
       " '不想': 334,\n",
       " '天': 335,\n",
       " '本来': 336,\n",
       " '不行': 337,\n",
       " '-': 338,\n",
       " '较': 339,\n",
       " '这是': 340,\n",
       " '另外': 341,\n",
       " '新': 342,\n",
       " '要求': 343,\n",
       " '无': 344,\n",
       " '免费': 345,\n",
       " '写': 346,\n",
       " '行': 347,\n",
       " '键盘': 348,\n",
       " '》': 349,\n",
       " '几天': 350,\n",
       " '太小': 351,\n",
       " '然后': 352,\n",
       " '《': 353,\n",
       " '自营': 354,\n",
       " '还好': 355,\n",
       " '商品': 356,\n",
       " '慢': 357,\n",
       " '卡': 358,\n",
       " '该': 359,\n",
       " '机场': 360,\n",
       " '可是': 361,\n",
       " '那个': 362,\n",
       " '退货': 363,\n",
       " '上网': 364,\n",
       " '叫': 365,\n",
       " ')': 366,\n",
       " '钱': 367,\n",
       " '甜': 368,\n",
       " '8': 369,\n",
       " '一定': 370,\n",
       " '走': 371,\n",
       " '内容': 372,\n",
       " '品牌': 373,\n",
       " '相信': 374,\n",
       " '呵呵': 375,\n",
       " ':': 376,\n",
       " '赠品': 377,\n",
       " '显示': 378,\n",
       " '划算': 379,\n",
       " '后来': 380,\n",
       " '很差': 381,\n",
       " '降价': 382,\n",
       " '绝对': 383,\n",
       " '早上': 384,\n",
       " '对于': 385,\n",
       " '设计': 386,\n",
       " '还要': 387,\n",
       " '几个': 388,\n",
       " '(': 389,\n",
       " '看着': 390,\n",
       " '您': 391,\n",
       " '好好': 392,\n",
       " '喝': 393,\n",
       " '送到': 394,\n",
       " '少': 395,\n",
       " '宝贝': 396,\n",
       " '地': 397,\n",
       " '牌子': 398,\n",
       " '谁': 399,\n",
       " '开': 400,\n",
       " '容易': 401,\n",
       " '卫生间': 402,\n",
       " '电脑': 403,\n",
       " '太差': 404,\n",
       " '装修': 405,\n",
       " '相当': 406,\n",
       " '好像': 407,\n",
       " '卖': 408,\n",
       " '搞': 409,\n",
       " '带': 410,\n",
       " '卖家': 411,\n",
       " '其实': 412,\n",
       " '机器': 413,\n",
       " '驱动': 414,\n",
       " '不了': 415,\n",
       " '餐厅': 416,\n",
       " '方面': 417,\n",
       " '无法': 418,\n",
       " '大堂': 419,\n",
       " '机子': 420,\n",
       " '下午': 421,\n",
       " '真心': 422,\n",
       " '听': 423,\n",
       " '基本': 424,\n",
       " '配置': 425,\n",
       " '赞': 426,\n",
       " '作者': 427,\n",
       " '点评': 428,\n",
       " '面料': 429,\n",
       " '情况': 430,\n",
       " '星': 431,\n",
       " '/': 432,\n",
       " '．': 433,\n",
       " '好多': 434,\n",
       " '看看': 435,\n",
       " '麻烦': 436,\n",
       " '人员': 437,\n",
       " '12': 438,\n",
       " '一本': 439,\n",
       " '严重': 440,\n",
       " '拿到': 441,\n",
       " '帮': 442,\n",
       " '出': 443,\n",
       " '第二次': 444,\n",
       " '订': 445,\n",
       " '没用': 446,\n",
       " '将': 447,\n",
       " '交通': 448,\n",
       " '铃声': 449,\n",
       " '手感': 450,\n",
       " '安装': 451,\n",
       " '假': 452,\n",
       " '标准': 453,\n",
       " '没什么': 454,\n",
       " '联系': 455,\n",
       " '小哥': 456,\n",
       " '出现': 457,\n",
       " '玩': 458,\n",
       " '流畅': 459,\n",
       " '清晰': 460,\n",
       " '分钟': 461,\n",
       " '空调': 462,\n",
       " '继续': 463,\n",
       " '以为': 464,\n",
       " '信赖': 465,\n",
       " '除了': 466,\n",
       " '最好': 467,\n",
       " '不够': 468,\n",
       " '评论': 469,\n",
       " '商家': 470,\n",
       " '退': 471,\n",
       " '2008': 472,\n",
       " '软件': 473,\n",
       " '明显': 474,\n",
       " '简直': 475,\n",
       " '提供': 476,\n",
       " '价钱': 477,\n",
       " '整体': 478,\n",
       " '放': 479,\n",
       " '员': 480,\n",
       " '告诉': 481,\n",
       " '运行': 482,\n",
       " '旧': 483,\n",
       " '当': 484,\n",
       " '爱': 485,\n",
       " '差不多': 486,\n",
       " '售后': 487,\n",
       " '一起': 488,\n",
       " '已': 489,\n",
       " '很小': 490,\n",
       " '隔音': 491,\n",
       " '生活': 492,\n",
       " '故事': 493,\n",
       " '想象': 494,\n",
       " '口感': 495,\n",
       " '中国': 496,\n",
       " '回来': 497,\n",
       " '个人': 498,\n",
       " '退房': 499,\n",
       " '老': 500,\n",
       " '好用': 501,\n",
       " '两天': 502,\n",
       " '唯一': 503,\n",
       " '经常': 504,\n",
       " '洗完': 505,\n",
       " '长': 506,\n",
       " '总之': 507,\n",
       " 'XP': 508,\n",
       " '30': 509,\n",
       " '视频': 510,\n",
       " '火龙果': 511,\n",
       " '头皮屑': 512,\n",
       " '原因': 513,\n",
       " '大床': 514,\n",
       " '老公': 515,\n",
       " '任何': 516,\n",
       " '漂亮': 517,\n",
       " '呀': 518,\n",
       " '618': 519,\n",
       " '反应': 520,\n",
       " '主要': 521,\n",
       " '发票': 522,\n",
       " '20': 523,\n",
       " '近': 524,\n",
       " '外面': 525,\n",
       " '介绍': 526,\n",
       " '不用': 527,\n",
       " '简单': 528,\n",
       " '预定': 529,\n",
       " '别人': 530,\n",
       " '按': 531,\n",
       " '—': 532,\n",
       " '为了': 533,\n",
       " '补充': 534,\n",
       " '每次': 535,\n",
       " '前': 536,\n",
       " '作为': 537,\n",
       " '订单': 538,\n",
       " '所有': 539,\n",
       " '9': 540,\n",
       " '散热': 541,\n",
       " '款': 542,\n",
       " '由于': 543,\n",
       " '三个': 544,\n",
       " '到货': 545,\n",
       " '通过': 546,\n",
       " '尤其': 547,\n",
       " '楼': 548,\n",
       " '原来': 549,\n",
       " '请': 550,\n",
       " '左右': 551,\n",
       " '多次': 552,\n",
       " '热情': 553,\n",
       " '不值': 554,\n",
       " '后悔': 555,\n",
       " '差劲': 556,\n",
       " '这些': 557,\n",
       " '蛮': 558,\n",
       " '家': 559,\n",
       " '几次': 560,\n",
       " '分辨率': 561,\n",
       " '读': 562,\n",
       " '看起来': 563,\n",
       " '再也': 564,\n",
       " '...': 565,\n",
       " '陈旧': 566,\n",
       " '必须': 567,\n",
       " '硬件': 568,\n",
       " '们': 569,\n",
       " '肯定': 570,\n",
       " '啥': 571,\n",
       " '够': 572,\n",
       " '估计': 573,\n",
       " '品质': 574,\n",
       " '差差': 575,\n",
       " '摄像头': 576,\n",
       " '五星': 577,\n",
       " '舒适': 578,\n",
       " '消费者': 579,\n",
       " '掉': 580,\n",
       " '同事': 581,\n",
       " '清扬': 582,\n",
       " '影响': 583,\n",
       " '下载': 584,\n",
       " '么': 585,\n",
       " '不知': 586,\n",
       " '体验': 587,\n",
       " '耳机': 588,\n",
       " '接受': 589,\n",
       " '配送': 590,\n",
       " '性能': 591,\n",
       " '客户': 592,\n",
       " '短信': 593,\n",
       " '那种': 594,\n",
       " '儿子': 595,\n",
       " '倒': 596,\n",
       " '分': 597,\n",
       " '地理位置': 598,\n",
       " '上面': 599,\n",
       " '本': 600,\n",
       " '款式': 601,\n",
       " '痒': 602,\n",
       " '当时': 603,\n",
       " '解决': 604,\n",
       " ';': 605,\n",
       " '样子': 606,\n",
       " '11': 607,\n",
       " '考虑': 608,\n",
       " '最差': 609,\n",
       " '豪华': 610,\n",
       " '昨天': 611,\n",
       " '买来': 612,\n",
       " '力': 613,\n",
       " '拍': 614,\n",
       " '字': 615,\n",
       " '床': 616,\n",
       " '本人': 617,\n",
       " '每个': 618,\n",
       " '及': 619,\n",
       " '头皮': 620,\n",
       " '工作': 621,\n",
       " '饭店': 622,\n",
       " '处理': 623,\n",
       " '刚刚': 624,\n",
       " '低': 625,\n",
       " '谢谢': 626,\n",
       " '公司': 627,\n",
       " '客房': 628,\n",
       " '一家': 629,\n",
       " '反正': 630,\n",
       " '游戏': 631,\n",
       " '内': 632,\n",
       " '讲': 633,\n",
       " '一看': 634,\n",
       " '尺码': 635,\n",
       " '价位': 636,\n",
       " '开机': 637,\n",
       " '事情': 638,\n",
       " '再次': 639,\n",
       " '怀疑': 640,\n",
       " '商务': 641,\n",
       " '不同': 642,\n",
       " '电影': 643,\n",
       " '升级': 644,\n",
       " '以': 645,\n",
       " '一条': 646,\n",
       " '才能': 647,\n",
       " '坑': 648,\n",
       " '算是': 649,\n",
       " '正常': 650,\n",
       " '丰富': 651,\n",
       " '死': 652,\n",
       " '郁闷': 653,\n",
       " '或': 654,\n",
       " '别的': 655,\n",
       " '安静': 656,\n",
       " '不太': 657,\n",
       " '越来越': 658,\n",
       " '一种': 659,\n",
       " '音质': 660,\n",
       " '当然': 661,\n",
       " '十分': 662,\n",
       " '找到': 663,\n",
       " '水': 664,\n",
       " '门口': 665,\n",
       " '完美': 666,\n",
       " '充电': 667,\n",
       " '附近': 668,\n",
       " '重要': 669,\n",
       " '之': 670,\n",
       " '更好': 671,\n",
       " '办法': 672,\n",
       " '每天': 673,\n",
       " '屏': 674,\n",
       " '恶心': 675,\n",
       " '不少': 676,\n",
       " '照片': 677,\n",
       " '如': 678,\n",
       " '清楚': 679,\n",
       " '店': 680,\n",
       " '上当': 681,\n",
       " '头': 682,\n",
       " '感谢': 683,\n",
       " '先': 684,\n",
       " '并且': 685,\n",
       " '哈哈': 686,\n",
       " '太慢': 687,\n",
       " '没想到': 688,\n",
       " '或者': 689,\n",
       " '所': 690,\n",
       " '期待': 691,\n",
       " '店家': 692,\n",
       " '像素': 693,\n",
       " '100': 694,\n",
       " '15': 695,\n",
       " '当天': 696,\n",
       " '发': 697,\n",
       " '缺点': 698,\n",
       " '此': 699,\n",
       " '那些': 700,\n",
       " '其它': 701,\n",
       " '说好': 702,\n",
       " '掉色': 703,\n",
       " '事': 704,\n",
       " '描述': 705,\n",
       " '毕竟': 706,\n",
       " '几乎': 707,\n",
       " '吵': 708,\n",
       " '花': 709,\n",
       " '不足': 710,\n",
       " '同时': 711,\n",
       " '套装': 712,\n",
       " '实用': 713,\n",
       " '不怎么样': 714,\n",
       " '窗户': 715,\n",
       " '刚买': 716,\n",
       " '三星': 717,\n",
       " '注意': 718,\n",
       " '电视': 719,\n",
       " '过来': 720,\n",
       " '卫生': 721,\n",
       " '妈妈': 722,\n",
       " '买回来': 723,\n",
       " '上次': 724,\n",
       " '就算': 725,\n",
       " '如何': 726,\n",
       " '给力': 727,\n",
       " '品种': 728,\n",
       " '如此': 729,\n",
       " '些': 730,\n",
       " '习惯': 731,\n",
       " '很漂亮': 732,\n",
       " '投诉': 733,\n",
       " '整个': 734,\n",
       " '首先': 735,\n",
       " '信号': 736,\n",
       " '一个月': 737,\n",
       " '准备': 738,\n",
       " '热': 739,\n",
       " '那里': 740,\n",
       " '设置': 741,\n",
       " '放心': 742,\n",
       " '也好': 743,\n",
       " '实际': 744,\n",
       " '脆': 745,\n",
       " '向': 746,\n",
       " '能够': 747,\n",
       " '次': 748,\n",
       " '四星': 749,\n",
       " '文字': 750,\n",
       " '一瓶': 751,\n",
       " '目前': 752,\n",
       " '还行': 753,\n",
       " '评差': 754,\n",
       " '说明': 755,\n",
       " '间': 756,\n",
       " '地毯': 757,\n",
       " '认为': 758,\n",
       " '久': 759,\n",
       " '加': 760,\n",
       " '多少': 761,\n",
       " '全': 762,\n",
       " '很甜': 763,\n",
       " '正好': 764,\n",
       " '可惜': 765,\n",
       " '死机': 766,\n",
       " '吃饭': 767,\n",
       " '宝宝': 768,\n",
       " '两次': 769,\n",
       " '牛奶': 770,\n",
       " '要是': 771,\n",
       " '稍微': 772,\n",
       " '反馈': 773,\n",
       " '遇到': 774,\n",
       " '用过': 775,\n",
       " '阅读': 776,\n",
       " '脏': 777,\n",
       " '优点': 778,\n",
       " '定': 779,\n",
       " '合身': 780,\n",
       " '膜': 781,\n",
       " '一般般': 782,\n",
       " '这款': 783,\n",
       " '感受': 784,\n",
       " '半天': 785,\n",
       " '不怎么': 786,\n",
       " '后面': 787,\n",
       " '只要': 788,\n",
       " '总是': 789,\n",
       " '待机时间': 790,\n",
       " '很棒': 791,\n",
       " '开心': 792,\n",
       " '了解': 793,\n",
       " '过去': 794,\n",
       " '电梯': 795,\n",
       " '不敢': 796,\n",
       " '一股': 797,\n",
       " '单': 798,\n",
       " '各种': 799,\n",
       " '上海': 800,\n",
       " '不爽': 801,\n",
       " '也许': 802,\n",
       " '\"': 803,\n",
       " '网购': 804,\n",
       " '机': 805,\n",
       " '拍照': 806,\n",
       " '普通': 807,\n",
       " '女儿': 808,\n",
       " '告知': 809,\n",
       " '管理': 810,\n",
       " '优惠': 811,\n",
       " '改进': 812,\n",
       " '按键': 813,\n",
       " '行李': 814,\n",
       " '黑': 815,\n",
       " '国产': 816,\n",
       " '不算': 817,\n",
       " '挺快': 818,\n",
       " '心情': 819,\n",
       " '理解': 820,\n",
       " '是否': 821,\n",
       " '飞机': 822,\n",
       " '最大': 823,\n",
       " '那样': 824,\n",
       " '操作': 825,\n",
       " '硬盘': 826,\n",
       " '信息': 827,\n",
       " '一段时间': 828,\n",
       " '一星': 829,\n",
       " '棒': 830,\n",
       " '有人': 831,\n",
       " '家里': 832,\n",
       " '重新': 833,\n",
       " '全部': 834,\n",
       " '回复': 835,\n",
       " '沙宣': 836,\n",
       " '全是': 837,\n",
       " '马上': 838,\n",
       " '弄': 839,\n",
       " '超值': 840,\n",
       " '其中': 841,\n",
       " '靠': 842,\n",
       " '破': 843,\n",
       " '送来': 844,\n",
       " '话': 845,\n",
       " '难吃': 846,\n",
       " '且': 847,\n",
       " '进行': 848,\n",
       " '块': 849,\n",
       " '小说': 850,\n",
       " '远': 851,\n",
       " '申请': 852,\n",
       " '安排': 853,\n",
       " '明明': 854,\n",
       " '玩游戏': 855,\n",
       " '价': 856,\n",
       " '经理': 857,\n",
       " '挺不错': 858,\n",
       " '的确': 859,\n",
       " '旁边': 860,\n",
       " '出差': 861,\n",
       " '有个': 862,\n",
       " '不太好': 863,\n",
       " '一张': 864,\n",
       " '毛巾': 865,\n",
       " '起': 866,\n",
       " '时尚': 867,\n",
       " '实体店': 868,\n",
       " '选': 869,\n",
       " '周围': 870,\n",
       " '同样': 871,\n",
       " '电': 872,\n",
       " '房价': 873,\n",
       " '难道': 874,\n",
       " '终于': 875,\n",
       " '唉': 876,\n",
       " '不买': 877,\n",
       " '自动': 878,\n",
       " '所谓': 879,\n",
       " '放在': 880,\n",
       " '每': 881,\n",
       " '酸': 882,\n",
       " '没法': 883,\n",
       " '及时': 884,\n",
       " '无语': 885,\n",
       " '跑': 886,\n",
       " '学习': 887,\n",
       " '小姐': 888,\n",
       " '色差': 889,\n",
       " '看来': 890,\n",
       " '哎': 891,\n",
       " '于是': 892,\n",
       " 'MP3': 893,\n",
       " '半个': 894,\n",
       " '布料': 895,\n",
       " '上午': 896,\n",
       " '^': 897,\n",
       " '进去': 898,\n",
       " '出去': 899,\n",
       " '书中': 900,\n",
       " '中午': 901,\n",
       " '这点': 902,\n",
       " '洗澡': 903,\n",
       " '打车': 904,\n",
       " '另': 905,\n",
       " '星级': 906,\n",
       " '手': 907,\n",
       " '平时': 908,\n",
       " '扔': 909,\n",
       " '总': 910,\n",
       " '楼层': 911,\n",
       " '刚好': 912,\n",
       " '部分': 913,\n",
       " '解释': 914,\n",
       " '世界': 915,\n",
       " '图': 916,\n",
       " '许多': 917,\n",
       " '于': 918,\n",
       " '光顾': 919,\n",
       " '早': 920,\n",
       " '关键': 921,\n",
       " '200': 922,\n",
       " '机身': 923,\n",
       " '不管': 924,\n",
       " '一句': 925,\n",
       " '晚': 926,\n",
       " '黑色': 927,\n",
       " '别': 928,\n",
       " '网络': 929,\n",
       " '人家': 930,\n",
       " '愉快': 931,\n",
       " '宽带': 932,\n",
       " '出门': 933,\n",
       " '版': 934,\n",
       " '一件': 935,\n",
       " '精致': 936,\n",
       " '真正': 937,\n",
       " '怎么样': 938,\n",
       " '其': 939,\n",
       " '回': 940,\n",
       " '未': 941,\n",
       " '通话': 942,\n",
       " '水分': 943,\n",
       " '买过': 944,\n",
       " '热水': 945,\n",
       " '超': 946,\n",
       " '包': 947,\n",
       " '一半': 948,\n",
       " '赠送': 949,\n",
       " '收费': 950,\n",
       " '一如既往': 951,\n",
       " '强': 952,\n",
       " '醉': 953,\n",
       " '有时': 954,\n",
       " '重': 955,\n",
       " '大概': 956,\n",
       " '出租车': 957,\n",
       " '经历': 958,\n",
       " '遗憾': 959,\n",
       " '距离': 960,\n",
       " '岁': 961,\n",
       " '薄': 962,\n",
       " '最近': 963,\n",
       " '16': 964,\n",
       " '播放': 965,\n",
       " '尺寸': 966,\n",
       " '总的来说': 967,\n",
       " '物美价廉': 968,\n",
       " '一套': 969,\n",
       " '极差': 970,\n",
       " '得到': 971,\n",
       " '嘛': 972,\n",
       " '哪里': 973,\n",
       " '各': 974,\n",
       " '车': 975,\n",
       " '箱子': 976,\n",
       " '第一': 977,\n",
       " '保护': 978,\n",
       " '比如': 979,\n",
       " '到位': 980,\n",
       " '键': 981,\n",
       " '明白': 982,\n",
       " '预订': 983,\n",
       " '像是': 984,\n",
       " '生鲜': 985,\n",
       " '北京': 986,\n",
       " '特色': 987,\n",
       " '看过': 988,\n",
       " '合理': 989,\n",
       " '音乐': 990,\n",
       " '下去': 991,\n",
       " '正在': 992,\n",
       " '设备': 993,\n",
       " '专业': 994,\n",
       " '确认': 995,\n",
       " '睡': 996,\n",
       " '印象': 997,\n",
       " '心里': 998,\n",
       " '是因为': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 利用word2idx、idx2word和w2v创建embedding矩阵，方便输入到模型中\n",
    "def create_embedding_matrix(word2idx,idx2word,w2v):\n",
    "    embedding_matrix = np.zeros((len(word2idx),100))\n",
    "    for word,index in word2idx.items():\n",
    "        try:\n",
    "            embedding_matrix[index,:] = w2v[word]\n",
    "        except:\n",
    "            embedding_matrix[index,:] = np.random.rand(100)\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = create_embedding_matrix(word2idx,idx2word,w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 利用embedding_matrix创建embedding层\n",
    "def create_embedding_layer(embedding_matrix):\n",
    "    embedding = nn.Embedding(embedding_matrix.shape[0],embedding_matrix.shape[1])\n",
    "    embedding.weight = nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = create_embedding_layer(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 通过sklearn函数,创建训练集和验证集\n",
    "def create_train_val_set(data_input,labels,val_size=0.1):\n",
    "    train_input,val_input,train_labels,val_labels = train_test_split(data_input,labels,test_size=val_size)\n",
    "    return train_input,val_input,train_labels,val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 生成训练集和验证集\n",
    "train_input,val_input,train_labels,val_labels = create_train_val_set(data_input,labels,val_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 创建训练和验证时用的dataset\n",
    "class modeldataset(Dataset):\n",
    "    def __init__(self,inputs,labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.inputs[index],self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = modeldataset(train_input,train_labels)\n",
    "val_dataset = modeldataset(val_input,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([4348, 5522, 2807, 2635, 3425,  393,  744, 4348, 1403, 5457, 2257,  420,\n",
      "        3425, 7185, 5089, 2302, 6010, 3805, 5398, 3783, 3783, 3389, 5089,  168,\n",
      "        7028, 3395, 2042, 1497, 1912, 3618, 1789, 6482]), tensor([6308,  494, 5854, 6880,  324,  393, 6760, 2948, 1271, 4056,  266, 3597,\n",
      "        7185, 3485, 3106, 2622, 4045, 4293, 1049, 5669, 4293, 4348, 6885, 1418,\n",
      "        2525, 1271, 4348, 5653, 4348, 7392, 3570, 6880]), tensor([2189, 4797, 4348, 1271, 1271,  393,  509,  817, 1403, 4348,  585, 4348,\n",
      "        7319, 6880, 7307, 6156, 6880, 2814, 1271, 1418, 4598, 1271, 2729, 6880,\n",
      "        1789,   17, 4384, 3363, 1787, 4772, 2189, 1271]), tensor([1659, 4348, 4190, 4717, 5402, 1271, 6926, 6880, 1271, 4348, 4032, 7204,\n",
      "        3570, 1271, 4363, 7185, 1899, 1271, 2812, 1271, 1271, 6239, 4348, 1271,\n",
      "        2640, 4617, 6057, 4348, 4348, 3490,  238, 3074]), tensor([1271, 4348, 4281, 6880, 3389, 4150, 1343, 2882,  981, 5307, 1388, 7077,\n",
      "        3117, 5242, 4348, 5662, 2406, 6121, 7392, 4293, 1218, 2257, 1271, 5359,\n",
      "        5774, 4348, 1546, 5346, 4348, 4348, 5584,  215]), tensor([6968, 4348, 4348, 1554, 1271, 4348, 6880, 4348, 1403, 4348, 1271, 4348,\n",
      "        2635, 6239, 4190, 6880, 4348, 4348, 4006, 2471, 7185, 3546,  181, 6565,\n",
      "          17, 1746, 1271, 1271, 4348, 7426, 1271, 1617]), tensor([4348, 4348,  744, 1604, 3201, 7177, 4348, 4348, 4348, 4813, 2039, 1271,\n",
      "        3570, 4348, 3433, 1271, 4729,  410, 4348, 1271, 6973, 6761, 4348, 4348,\n",
      "         234, 1298,  168, 6184, 5297, 1617, 6352, 7368]), tensor([7166, 4348, 1388, 4348, 5948, 6968, 4348, 3333, 4348, 4502, 7111,  990,\n",
      "        4348, 1271, 6885, 2504, 1816, 2358, 4348, 4717, 4348, 4348, 1138, 6057,\n",
      "        1271, 3519, 4193, 3106, 5297, 6760, 6656, 4348]), tensor([4348, 4348, 4190, 4348, 3389, 2134, 6952, 1271, 4348, 5868, 1271, 6880,\n",
      "        4348, 2525, 3389, 1311, 6362, 2729, 4348, 1388, 4348, 1271, 4099, 6885,\n",
      "         255, 1271, 1110, 4348, 7202, 6209, 7392, 2335]), tensor([2640, 4348, 1092, 4348, 1271, 1271, 3106, 5952, 4348, 5457, 4247, 4348,\n",
      "        4348, 6880, 4190,  473, 6362, 6880, 4348, 6880, 4348, 7256,  982,  406,\n",
      "         838, 5089, 2610, 4382, 7392, 2640, 6760, 1718]), tensor([4348, 4348, 1340, 4348, 2985, 2942, 4813, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 5242, 1699, 6407, 4994, 4348, 4348, 2326, 4348, 2042,  817, 1789,\n",
      "        7028,  682,  817, 4348,   41, 2640, 5762, 4348]), tensor([4348, 4348, 4348, 4348, 2615,  975, 4348, 2249, 4348, 1271, 7242, 4348,\n",
      "        4348, 1617, 3201, 4348, 1007, 4348, 4348, 4363, 4348, 7237, 2533, 6880,\n",
      "        1271, 7144,  788, 1271,  545, 4348, 1579,  209]), tensor([4348, 4348, 5250, 4348, 4348,  872, 4348, 5239, 4348,  981, 2273, 4348,\n",
      "        4348, 3682, 5868, 4348, 6239, 4348, 4348, 2897, 4348, 4384, 3293, 5302,\n",
      "        6952,   17, 2273, 2273, 2273, 4236,  238, 4348]), tensor([4348, 4348, 2117, 4348, 4348, 6327, 4348, 4348, 4348,    4, 4309, 4348,\n",
      "        4348, 4348, 4348, 4348, 1310, 4348, 4348, 1271, 4348, 1546, 1271, 4348,\n",
      "        3106, 1298, 3748, 6611, 4553, 4951, 5584,  215]), tensor([4348, 4348, 4348, 4348, 4348, 1271, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 6880, 4348, 4348, 6057, 4348, 1271, 4348, 4348,\n",
      "        4938, 3570, 1271, 4348, 5297, 2259, 3570, 2640]), tensor([4348, 4348, 7024, 4348, 4348, 5089, 4348, 4348, 4348, 5372, 4348, 4348,\n",
      "        4348, 4348, 1164, 4348, 6362, 4348, 4348, 1819, 4348, 5853, 7152, 4348,\n",
      "        4348, 2358, 1026, 4348, 5297, 6278, 3570, 5089]), tensor([4348, 4348,  959, 4348, 4348, 5446, 4348, 6407, 4348, 2640, 4348, 4348,\n",
      "        4348, 4348, 4190, 4348, 6362, 4348, 4348, 4247, 4348, 3748, 1271, 4348,\n",
      "        2640, 3106, 2273, 4348, 7161, 5868, 3663, 1617]), tensor([4348, 4348, 3689, 4348, 4348,  952, 4348, 1271, 4348, 7416, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 5786, 4348, 1271, 6885, 4348,\n",
      "        1298, 5089, 2844, 4348, 1787, 4233, 6760, 6968]), tensor([4348, 4348, 3056, 4348, 4348, 1617, 4348, 5621, 4348, 3106, 4348, 4348,\n",
      "        4348, 4348, 4190, 4348, 4348, 4348, 4348, 4348, 4348,  682, 2273, 4348,\n",
      "        3389, 5242, 1271, 4348, 4179, 6880, 3182, 2042]), tensor([4348, 4348, 4348, 4348, 4348, 4006, 4348, 3585, 4348, 4056, 4348, 4348,\n",
      "        4348, 4348,  549, 4348, 4348, 4348, 4348, 4348, 4348, 3690, 3106, 4348,\n",
      "        1271, 6278, 3585, 4348, 4348, 4348, 3412,  987]), tensor([4348, 4348, 3425, 4348, 4348, 1271, 4348, 4348, 4348, 1341, 4348, 4348,\n",
      "        4348, 4348, 6889, 4348, 4348, 4348, 4348, 4348, 4348, 1271,  393, 4348,\n",
      "        2284, 2042, 4299, 4348, 6880, 4348, 6239, 6206]), tensor([4348, 4348, 4348, 4348, 4348, 6952, 4348, 4348, 4348, 4947, 4348, 4348,\n",
      "        4348, 4348, 7232, 4348, 4348, 4348, 4348, 4348, 4348, 7334, 2640, 4348,\n",
      "        4575, 3243, 3210, 4348, 1271, 4348, 6558, 3748]), tensor([4348, 4348, 4348, 4348, 4348, 7204, 4348, 1271, 4348, 1271, 4348, 4348,\n",
      "        4348, 4348, 4190, 4348, 4348, 4348, 4348, 4348, 4348, 5491, 1381, 4348,\n",
      "        4348, 4348, 3389, 4348,  981, 4348, 5601, 6880]), tensor([4348, 4348, 4348, 4348, 4348, 2022, 4348,  788, 4348, 6160, 4348, 4348,\n",
      "        4348, 4348, 4322, 4348, 4348, 4348, 4348, 4348, 4348, 2042, 4434, 4348,\n",
      "        4348, 3207, 1271, 4348, 4348, 4348, 6278, 1271]), tensor([4348, 4348, 4348, 4348, 4348, 5446, 4348, 6528, 4348,  393, 4348, 4348,\n",
      "        4348, 4348,  569, 4348, 4348, 4348, 4348, 4348, 4348, 6076, 4348, 4348,\n",
      "        4348, 2930, 2273, 4348, 5297, 4348, 2358, 7432]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 5994, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 1271, 3748, 4348, 5297, 4348, 6239, 4293]), tensor([4348, 4348, 4348, 4348, 4348, 1271, 4348,  908, 4348, 2197, 4348, 4348,\n",
      "        4348, 4348, 5117, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 6880, 4348,\n",
      "        4348, 6224, 2640, 4348, 2358, 4348,  289,  682]), tensor([4348, 4348, 4348, 4348, 4348, 6760, 4348, 2108, 4348,  211, 4348, 4348,\n",
      "        4348, 4348, 6709, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271, 4348,\n",
      "        4348, 4762, 6057, 4348, 6806, 4348, 3570, 2615]), tensor([4348, 4348, 4348, 4348, 4348, 1717, 4348, 4566, 4348, 6788, 4348, 4348,\n",
      "        4348, 4348, 1579, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 7336, 4348,\n",
      "        4348, 2814, 6656, 4348, 5297, 4348,  393, 1271]), tensor([4348, 4348, 4348, 4348, 4348, 2640, 4348, 2273, 4348, 5330, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,  114, 4348,\n",
      "        4348, 6968, 4348, 4348, 5297, 4348, 4348,   17]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 6889, 4348, 6308, 4348, 4348,\n",
      "        4348, 4348, 4190, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 5310, 4348,\n",
      "        4348, 3106, 7330, 4348, 4348, 4348, 7392, 6709]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 2057, 4348, 4348,\n",
      "        4348, 4348, 5956, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 5426, 4348,\n",
      "        4348, 6564, 4339, 4348, 4348, 4348, 4905, 4156]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 2640, 4348, 2640, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 2640, 4348,\n",
      "        4348, 3570, 2379, 4348, 4348, 4348, 6239, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 3045, 4348, 7467, 4348, 4348,\n",
      "        4348, 4348, 3425, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 6680, 4348,\n",
      "        4348, 3117, 3750, 4348, 4348, 4348, 3570, 2640]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 7185, 4348, 4348,\n",
      "        4348, 4348, 3389, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348,  682, 1090, 4348, 4348, 4348, 3570, 1127]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 6968, 4348, 7319, 4348, 4348,\n",
      "        4348, 4348, 4190, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 3901, 4348,\n",
      "        4348, 1546, 3570, 4348, 4348, 4348, 3570,  987]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271, 4348, 4348,\n",
      "        4348, 4348, 6057, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271, 4348,\n",
      "        4348, 1271, 3570, 4348, 4348, 4348, 4348,  817]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 6785, 4348, 3630, 4348, 4348,\n",
      "        4348, 4348, 4097, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 5089, 4348,\n",
      "        4348, 2257, 1617, 4348, 4348, 4348, 4348, 3277]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 5239, 4348, 2273, 4348, 4348,\n",
      "        4348, 4348, 3931, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 6963, 4348,\n",
      "        4348, 6073, 5310, 4348, 4348, 4348, 4348, 1271]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 6880, 4348, 3514, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 3277, 4348,\n",
      "        4348, 3570, 4348, 4348, 4348, 4348, 4348, 3435]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271, 4348, 4348,\n",
      "        4348, 4348, 4190, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348,  461]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,  987, 4348, 4348,\n",
      "        4348, 4348, 4322, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1559, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348,   17]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 7157, 4348, 5767, 4348, 4348,\n",
      "        4348, 4348,  975, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 3106, 4348,\n",
      "        4348, 4348, 1271, 4348, 4348, 4348, 4348, 4239]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 7330, 4348, 4348, 4348, 4348, 7204]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271, 4348,  404, 4348, 4348,\n",
      "        4348, 4348, 4293, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 6880, 4348,\n",
      "        4348, 4348, 7392, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 5148, 4348, 2492, 4348, 4348,\n",
      "        4348, 4348, 1616, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271, 4348,\n",
      "        4348, 4348,  987, 4348, 4348, 4348, 4348,  289]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 2537, 4348, 4348,\n",
      "        4348, 4348, 3182, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 2332, 4348,\n",
      "        4348, 4348, 1979, 4348, 4348, 4348, 4348, 1271]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 6428, 4348, 1271, 4348, 4348,\n",
      "        4348, 4348, 4190, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 2042, 4348,\n",
      "        4348, 4348, 3748, 4348, 4348, 4348, 4348, 2416]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271, 4348, 6993, 4348, 4348,\n",
      "        4348, 4348,  883, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 7247, 4348,\n",
      "        4348, 4348, 7392, 4348, 4348, 4348, 4348, 6952]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4896, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 2814, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271, 4348,\n",
      "        4348, 4348, 1546, 4348, 4348, 4348, 4348, 6760]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 5787, 4348, 6249, 4348, 4348,\n",
      "        4348, 4348, 7466, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 2042, 4348,\n",
      "        4348, 4348, 4644, 4348, 4348, 4348, 4348, 2131]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 6709, 4348, 4348,\n",
      "        4348, 4348, 4190, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4321, 4348,\n",
      "        4348, 4348, 6880, 4348, 4348, 4348, 4348, 4220]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 7219, 4348, 1847, 4348, 4348,\n",
      "        4348, 4348, 5025, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 6880, 4348,\n",
      "        4348, 4348, 2640, 4348, 4348, 4348, 4348, 2640]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 2640, 4348, 6880, 4348, 4348,\n",
      "        4348, 4348, 1093, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 2640, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 5813]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348,  621, 4348, 2640, 4348, 4348,\n",
      "        4348, 4348, 5356, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 6495, 4348, 7200, 4348, 4348,\n",
      "        4348, 4348, 1617, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 3490, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 1579]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 2326, 4348, 4348,\n",
      "        4348, 4348, 2814, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348,  181]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 2525, 4348, 4348,\n",
      "        4348, 4348, 2083, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 6952, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4859]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 3931, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1874, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4155, 4348, 1617, 4348, 4348,\n",
      "        4348, 4348, 4190, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 5692, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 5089]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,  497, 4348, 4348,\n",
      "        4348, 4348, 1192, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 6362, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4650]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 5793, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 6633, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 6362, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4069]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 2358, 4348, 4348,\n",
      "        4348, 4348, 3912, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 6362, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1290, 4348, 4348,\n",
      "        4348, 4348, 4190, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 6362, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348,  241]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4793, 4348, 6880, 4348, 4348,\n",
      "        4348, 4348, 4341, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 6362, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 5116]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 5868, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 1579, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 7406, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 6880]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 6695, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 2608, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 5982, 4348, 4348, 4348, 4348, 4348, 4348, 4348,  170, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 5310]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4293, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 2481, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 1115, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348,  629]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 1271, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 6115, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 3570, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 5472]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348,  962, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 3146]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 5793, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 3455]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 3220]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348,   41]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 7364, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348,  114]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4793, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 5239]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 7024, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4268]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 6968, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 3146]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348,  838, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 3455]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 1513, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 1547, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 3630, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 5297, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 5297, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348]), tensor([4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348,\n",
      "        4348, 4348, 4348, 4348, 4348, 4348, 4348, 4348])] ('0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '0', '0', '0', '0', '0')\n"
     ]
    }
   ],
   "source": [
    "### 创建训练和验证时用的dataloader\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "for idx,(batch_x,batch_y) in enumerate(train_dataloader):\n",
    "    print(batch_x,batch_y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 创建AttBiLSTM模型,结合上面的embedding层\n",
    "class AttBiLSTM(nn.Module):\n",
    "    def __init__(self,embedding_layer,vocab_size,embedding_dim,hidden_dim,num_classes=2,dropout=0.5):\n",
    "        super(AttBiLSTM,self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.embedding_layer = embedding_layer\n",
    "        self.lstm = nn.LSTM(embedding_dim,self.hidden_dim,batch_first=True,bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(in_features=self.hidden_dim*2,out_features=self.num_classes)\n",
    "    \n",
    "    ### 创建自注意力层,lstm_output : [batch_size, n_step, n_hidden * num_directions(=2)], F matrix\n",
    "    def attention(self,lstm_output, final_state):\n",
    "        hidden = final_state.view(-1,self.hidden_dim*2,1) ### [batch_size, n_hidden * num_directions(=2), 1]\n",
    "        att_weight = torch.bmm(lstm_output,hidden).squeeze(2) ### [batch_size, n_step]\n",
    "        soft_att_weight = F.softmax(att_weight,dim=1) ### [batch_size, n_step]\n",
    "        att_output = torch.bmm(lstm_output.transpose(1,2),soft_att_weight.unsqueeze(2)).squeeze(2) ### [batch_size, n_hidden * num_directions(=2)]\n",
    "        return att_output,soft_att_weight.data.numpy() ### [batch_size, n_hidden * num_directions(=2)]\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        embedding_output = self.embedding_layer(inputs) ### [batch_size, n_step, embedding_dim]\n",
    "\n",
    "        lstm_output,(final_hidden_state,final_cell_state) = self.lstm(embedding_output) ### [batch_size, n_step, n_hidden * num_directions(=2)]\n",
    "\n",
    "        att_output,att_weight = self.attention(lstm_output,final_hidden_state) ### [batch_size, n_hidden * num_directions(=2)]\n",
    "\n",
    "        dropout_output = self.dropout(att_output)\n",
    "        fc_output = self.fc(dropout_output)\n",
    "        return fc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 训练AttBiLSTM模型\n",
    "def train_model(model,train_dataset,batch_size=32,epochs=10,lr=0.001,weight_decay=0.001):\n",
    "    print(len(lr))\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "\n",
    "    ### 最佳损失值和最佳准确率\n",
    "    best_loss = 1e10\n",
    "    best_acc = 0\n",
    "\n",
    "    ### 创建训练数据\n",
    "    train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        ### 训练\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        model.train()\n",
    "        for step,(batch_x,batch_y) in enumerate(train_loader):\n",
    "            batch_x = Variable(batch_x)\n",
    "            batch_y = Variable(batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = loss_func(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.data[0]\n",
    "\n",
    "            _,pred = torch.max(outputs.data,1)\n",
    "            y_true.extend(labels.data.numpy().tolist())\n",
    "            y_pred.extend(pred.numpy().tolist())\n",
    "            train_acc += (pred == labels).sum()\n",
    "\n",
    "        train_loss_list.append(train_loss/len(train_input))\n",
    "        train_acc_list.append(train_acc/len(train_input))\n",
    "\n",
    "        print('Epoch: {}, Train Loss: {:.4f}, Train Acc: {:.4f}'.format(epoch+1,train_loss/len(train_input),train_acc/len(train_input)))\n",
    "\n",
    "        ### 当前如果是最佳损失值和最佳准确率，则保存模型\n",
    "        if train_loss/len(train_input) < best_loss:\n",
    "            best_loss = train_loss/len(train_input)\n",
    "            torch.save(model.state_dict(),'best_model.pth')\n",
    "\n",
    "        if train_acc/len(train_input) > best_acc:\n",
    "            best_acc = train_acc/len(train_input)\n",
    "            torch.save(model.state_dict(),'best_model_acc.pth')\n",
    "    \n",
    "    return train_loss_list,train_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = embedding_matrix.shape[1]\n",
    "hidden_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6278\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'float' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_760/1222437111.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### 创建AttBiLSTM模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAttBiLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_760/3403834985.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_dataset, batch_size, epochs, lr, weight_decay)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mloss_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\work-software\\anaconda\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[0;32m     34\u001b[0m     def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n\u001b[0;32m     35\u001b[0m                  weight_decay=0, amsgrad=False):\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid learning rate: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'float' and 'list'"
     ]
    }
   ],
   "source": [
    "### 创建AttBiLSTM模型\n",
    "model = AttBiLSTM(embedding_layer=embedding,vocab_size=embedding_matrix.shape[0],embedding_dim=embedding_matrix.shape[1],hidden_dim=hidden_dim)\n",
    "train_model(model,train_input,train_labels,val_input,val_labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "deb0106b308657f51f668daee95bb9c892872707c95f455b79d8e00bf6cd6d27"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
